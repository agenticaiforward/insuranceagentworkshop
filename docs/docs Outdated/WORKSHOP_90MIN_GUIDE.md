# ðŸŽ“ Agentic AI Workshop: 90-Minute Build Guide
**Enterprise Insurance Agent with Google AI Stack**

---

## ðŸ“‹ Workshop Overview

**Duration**: 90 minutes  
**Goal**: Build and deploy a complete Agentic AI system using Google's ecosystem  
**Stack**: Google AI Studio â†’ LangGraph â†’ RAG (Chroma) â†’ Vertex AI/Cloud Run

**What You'll Build**:
- Conversational insurance agent with multi-step reasoning
- RAG-powered knowledge base
- Document upload with Gemini Vision
- Production-ready deployment

---

## ðŸŽ¯ Learning Objectives

1. Understand 6 core Agentic AI principles
2. Use Google AI Studio for prototyping
3. Build orchestration with LangGraph
4. Implement RAG with Chroma + Gemini embeddings
5. Deploy to Vertex AI or Cloud Run

---

## â° 90-Minute Timeline

| Time | Section | Activity |
|------|---------|----------|
| 0:00-0:15 | **Part 1** | Principles & Architecture |
| 0:15-0:35 | **Part 2** | Google AI Studio Setup |
| 0:35-1:00 | **Part 3** | Build LangGraph Agent |
| 1:00-1:15 | **Part 4** | Add RAG System |
| 1:15-1:25 | **Part 5** | Frontend Integration |
| 1:25-1:30 | **Part 6** | Deployment & Wrap-up |

---

# Part 1: Principles & Architecture (15 min)

## The 6 Agentic AI Principles

### 1. **Autonomy** ðŸ¤–
Agent decides its own next steps based on context.

**Example**:
```
Traditional Bot: "What's your age?"
Agentic AI: [Analyzes context] "I see you drive a 2020 Honda. 
             Are you the primary driver, and how old are you?"
```

### 2. **Reasoning** ðŸ§ 
Multi-step decision making with conditional logic.

```
User: "I need car insurance"
Agent thinks:
â”œâ”€> Missing: age, vehicle, history
â”œâ”€> Action: Gather info
â””â”€> Once complete â†’ Calculate quote
```

### 3. **Tool Use** ðŸ› ï¸
Autonomously calls functions when needed.

```python
Agent decides: "I have enough info"
â†’ Calls calculate_auto_premium(age=28, vehicle_year=2020)
â†’ Returns structured quote
```

### 4. **Memory** ðŸ’­
Maintains conversation history and context.

### 5. **Planning** ðŸ“Š
Uses graph workflow (not linear flow).

### 6. **Learning** ðŸ“š
Searches knowledge base via RAG.

---

## System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  DEVELOPMENT WORKFLOW                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                 â”‚
â”‚  1. Google AI Studio (Prototyping)              â”‚
â”‚     â””â”€> Get API key (FREE)                      â”‚
â”‚     â””â”€> Test prompts                            â”‚
â”‚                                                 â”‚
â”‚  2. LangGraph (Orchestration)                   â”‚
â”‚     â””â”€> Define nodes (gather, search, calc)    â”‚
â”‚     â””â”€> Add conditional edges                   â”‚
â”‚                                                 â”‚
â”‚  3. RAG System (Knowledge)                      â”‚
â”‚     â””â”€> Chroma DB (local vector store)         â”‚
â”‚     â””â”€> Gemini embeddings                       â”‚
â”‚                                                 â”‚
â”‚  4. Deployment (Production)                     â”‚
â”‚     â””â”€> Vertex AI or Cloud Run                 â”‚
â”‚                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# Part 2: Google AI Studio Setup (20 min)

## Step 1: Get Your FREE Gemini API Key

1. **Navigate to**: https://aistudio.google.com/
2. **Click**: "Get API Key" (top right)
3. **Create new key** or use existing project
4. **Copy** the API key (starts with `AIza...`)

**âš ï¸ Important**: No credit card required! Free tier includes:
- 1,500 requests/day for Gemini 1.5 Flash
- Unlimited embeddings

---

## Step 2: Test in AI Studio

**Try this prompt**:
```
You are an insurance agent. A user says: "I'm 28, drive a 2020 Honda Civic, 
licensed for 10 years, no accidents."

Extract the following information:
- Age
- Vehicle year
- Vehicle make/model
- Years licensed
- Accidents

Return as JSON.
```

**Expected output**:
```json
{
  "age": 28,
  "vehicle_year": 2020,
  "vehicle_make": "Honda",
  "vehicle_model": "Civic",
  "years_licensed": 10,
  "accidents": 0
}
```

**Key Learning**: AI Studio lets you prototype before coding!

---

## Step 3: Project Setup

**Create project directory**:
```bash
mkdir insurance-agent
cd insurance-agent
mkdir backend frontend
```

**Backend setup**:
```bash
cd backend
python -m venv venv

# Windows
venv\Scripts\activate

# Mac/Linux
source venv/bin/activate

# Install dependencies
pip install langchain langgraph langchain-google-genai \
            langchain-chroma chromadb fastapi uvicorn \
            python-dotenv pillow
```

**Create `.env` file**:
```bash
echo "GEMINI_API_KEY=your_api_key_here" > .env
```

---

# Part 3: Build LangGraph Agent (25 min)

## Step 4: Create Agent State

**File**: `backend/agent_state.py`

```python
from typing import TypedDict, Sequence
from langchain.schema import HumanMessage, AIMessage
import operator
from typing import Annotated

class AgentState(TypedDict):
    """State that flows through the graph"""
    messages: Annotated[Sequence[HumanMessage | AIMessage], operator.add]
    user_info: dict
    insurance_type: str  # 'auto' or 'home'
    quote_result: dict
    knowledge_context: str
    next_action: str
```

**Explanation**:
- `messages`: Conversation history (Memory principle)
- `user_info`: Extracted details (age, vehicle, etc.)
- `next_action`: What the agent should do next (Planning principle)

---

## Step 5: Define Tools

**File**: `backend/tools.py`

```python
from langchain.tools import tool

@tool
def calculate_auto_premium(
    age: int,
    vehicle_year: int,
    years_licensed: int,
    accidents: int = 0,
    violations: int = 0
) -> dict:
    """Calculate auto insurance premium"""
    
    base_rate = 800
    
    # Age factor
    if age < 25:
        age_factor = 400
    elif age < 30:
        age_factor = 200
    else:
        age_factor = 0
    
    # Experience discount
    experience_factor = -100 if years_licensed > 10 else 0
    
    # Accident/violation surcharges
    accident_factor = accidents * 300
    violation_factor = violations * 200
    
    annual_premium = (base_rate + age_factor + experience_factor + 
                     accident_factor + violation_factor)
    monthly_premium = round(annual_premium / 12, 2)
    
    return {
        "monthly_premium": monthly_premium,
        "annual_premium": annual_premium,
        "breakdown": {
            "base_rate": base_rate,
            "age_adjustment": age_factor,
            "experience_discount": experience_factor,
            "accident_surcharge": accident_factor,
            "violation_surcharge": violation_factor
        }
    }
```

**Test it**:
```python
result = calculate_auto_premium.invoke({
    "age": 28,
    "vehicle_year": 2020,
    "years_licensed": 10,
    "accidents": 0
})
print(result)
# Output: {'monthly_premium': 75.0, 'annual_premium': 900, ...}
```

---

## Step 6: Create Graph Nodes

**File**: `backend/graph_nodes.py`

```python
from langchain_google_genai import ChatGoogleGenerativeAI
from agent_state import AgentState
import os

llm = ChatGoogleGenerativeAI(
    model="gemini-1.5-flash",
    google_api_key=os.getenv("GEMINI_API_KEY")
)

def gather_info_node(state: AgentState) -> AgentState:
    """Node: Gather information through conversation"""
    print("ðŸ”µ NODE: gather_info")
    
    # Use LLM to continue conversation
    # In production, this would analyze messages and extract info
    
    state["next_action"] = "check_if_ready"
    return state

def calculate_quote_node(state: AgentState) -> AgentState:
    """Node: Calculate insurance quote"""
    print("ðŸ”µ NODE: calculate_quote")
    
    from tools import calculate_auto_premium
    
    user_info = state.get("user_info", {})
    result = calculate_auto_premium.invoke(user_info)
    
    state["quote_result"] = result
    state["next_action"] = "explain_quote"
    
    print(f"   ðŸ’° Premium: ${result['monthly_premium']}/month")
    return state

def explain_results_node(state: AgentState) -> AgentState:
    """Node: Explain the quote to user"""
    print("ðŸ”µ NODE: explain_results")
    
    state["next_action"] = "complete"
    return state
```

---

## Step 7: Build the Graph

**File**: `backend/langgraph_agent.py`

```python
from langgraph.graph import StateGraph, END
from agent_state import AgentState
from graph_nodes import gather_info_node, calculate_quote_node, explain_results_node

def should_calculate(state: AgentState) -> str:
    """Conditional edge: Decide next step"""
    
    user_info = state.get("user_info", {})
    
    # Check if we have enough info to calculate
    required_fields = ["age", "vehicle_year", "years_licensed"]
    
    if all(field in user_info for field in required_fields):
        return "calculate"
    else:
        return "gather_more"

# Create the graph
workflow = StateGraph(AgentState)

# Add nodes
workflow.add_node("gather_info", gather_info_node)
workflow.add_node("calculate_quote", calculate_quote_node)
workflow.add_node("explain_results", explain_results_node)

# Set entry point
workflow.set_entry_point("gather_info")

# Add conditional edges
workflow.add_conditional_edges(
    "gather_info",
    should_calculate,
    {
        "calculate": "calculate_quote",
        "gather_more": "gather_info"  # Loop back
    }
)

# Add regular edges
workflow.add_edge("calculate_quote", "explain_results")
workflow.add_edge("explain_results", END)

# Compile
agent_graph = workflow.compile()

# Test it
if __name__ == "__main__":
    result = agent_graph.invoke({
        "messages": [],
        "user_info": {
            "age": 28,
            "vehicle_year": 2020,
            "years_licensed": 10
        },
        "insurance_type": "auto"
    })
    print(result)
```

**Run it**:
```bash
python langgraph_agent.py
```

**Expected output**:
```
ðŸ”µ NODE: gather_info
ðŸ”µ NODE: calculate_quote
   ðŸ’° Premium: $75.0/month
ðŸ”µ NODE: explain_results
```

---

# Part 4: Add RAG System (15 min)

## Step 8: Create Knowledge Base

**File**: `backend/rag_system.py`

```python
from langchain_chroma import Chroma
from langchain_google_genai import GoogleGenerativeAIEmbeddings
from langchain.schema import Document
import os

# Insurance knowledge base
INSURANCE_KNOWLEDGE = {
    "auto_coverage": [
        "Collision coverage pays for damage to YOUR vehicle when you hit another vehicle or object.",
        "Comprehensive coverage pays for damage to your vehicle from non-collision events like theft, vandalism, weather, or animal strikes.",
        "Liability coverage pays for damage YOU cause to others (bodily injury and property damage)."
    ],
    "home_coverage": [
        "Dwelling coverage pays to repair or rebuild your home if it's damaged by covered perils.",
        "Personal property coverage pays to replace your belongings if they're stolen or damaged.",
        "Liability coverage protects you if someone is injured on your property."
    ],
    "discounts": [
        "Multi-policy discount: Save 10-25% by bundling auto and home insurance.",
        "Good driver discount: No accidents or violations in 3+ years can save 15-30%.",
        "Safety features: Anti-theft devices, airbags, and anti-lock brakes can reduce premiums."
    ]
}

# Initialize embeddings
embeddings = GoogleGenerativeAIEmbeddings(
    model="models/embedding-001",
    google_api_key=os.getenv("GEMINI_API_KEY")
)

def initialize_knowledge_base():
    """Create vector store from knowledge base"""
    
    documents = []
    for category, items in INSURANCE_KNOWLEDGE.items():
        for item in items:
            documents.append(Document(
                page_content=item,
                metadata={"category": category}
            ))
    
    vectorstore = Chroma.from_documents(
        documents,
        embeddings,
        persist_directory="./insurance_knowledge_db"
    )
    
    return vectorstore

def search_knowledge(query: str, k: int = 2):
    """Search knowledge base"""
    
    vectorstore = Chroma(
        persist_directory="./insurance_knowledge_db",
        embedding_function=embeddings
    )
    
    results = vectorstore.similarity_search(query, k=k)
    return results

# Initialize on import
try:
    vectorstore = initialize_knowledge_base()
    print("âœ… Knowledge base initialized")
except Exception as e:
    print(f"âš ï¸ Knowledge base will be created on first use: {e}")
```

**Test it**:
```python
from rag_system import search_knowledge

results = search_knowledge("What is collision coverage?")
for doc in results:
    print(doc.page_content)
```

---

## Step 9: Add RAG Node to Graph

**Update** `graph_nodes.py`:

```python
def search_knowledge_node(state: AgentState) -> AgentState:
    """Node: Search knowledge base"""
    print("ðŸ”µ NODE: search_knowledge")
    
    from rag_system import search_knowledge
    
    last_message = state["messages"][-1].content if state["messages"] else ""
    results = search_knowledge(last_message, k=2)
    
    context = "\n\n".join([doc.page_content for doc in results])
    state["knowledge_context"] = context
    
    print(f"   ðŸ“š Found {len(results)} relevant documents")
    
    state["next_action"] = "respond_with_context"
    return state
```

**Update** `langgraph_agent.py` to include RAG node:

```python
# Add to workflow
workflow.add_node("search_knowledge", search_knowledge_node)

# Update conditional logic
def should_search_or_calculate(state: AgentState) -> str:
    last_message = state["messages"][-1].content.lower() if state["messages"] else ""
    
    # Check if user is asking a question
    if any(keyword in last_message for keyword in ["what is", "explain", "tell me"]):
        return "search"
    
    # Check if ready to calculate
    user_info = state.get("user_info", {})
    if all(field in user_info for field in ["age", "vehicle_year", "years_licensed"]):
        return "calculate"
    
    return "gather_more"

# Update edges
workflow.add_conditional_edges(
    "gather_info",
    should_search_or_calculate,
    {
        "search": "search_knowledge",
        "calculate": "calculate_quote",
        "gather_more": "gather_info"
    }
)

workflow.add_edge("search_knowledge", "gather_info")
```

---

# Part 5: Frontend Integration (10 min)

## Step 10: Create FastAPI Backend

**File**: `backend/main.py`

```python
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import uuid
from langgraph_agent import agent_graph
from langchain.schema import HumanMessage, AIMessage

app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

sessions = {}

class ChatRequest(BaseModel):
    message: str
    session_id: str = None

@app.post("/api/chat")
async def chat(request: ChatRequest):
    session_id = request.session_id or str(uuid.uuid4())
    
    if session_id not in sessions:
        sessions[session_id] = {
            "messages": [],
            "user_info": {},
            "insurance_type": None
        }
    
    session = sessions[session_id]
    session["messages"].append(HumanMessage(content=request.message))
    
    # Run through agent graph
    result = agent_graph.invoke(session)
    
    # Get agent response (simplified)
    agent_response = f"Received: {request.message}"
    
    return {
        "response": agent_response,
        "session_id": session_id
    }

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
```

**Run it**:
```bash
python main.py
```

**Test**:
```bash
curl -X POST http://localhost:8000/api/chat \
  -H "Content-Type: application/json" \
  -d '{"message": "I need car insurance"}'
```

---

# Part 6: Deployment & Wrap-up (5 min)

## Deployment Options

### Option 1: Cloud Run (Recommended for Quick Deploy)

**Create** `Dockerfile`:
```dockerfile
FROM python:3.11-slim

WORKDIR /app
COPY backend/requirements.txt .
RUN pip install -r requirements.txt

COPY backend/ .

CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8080"]
```

**Deploy**:
```bash
gcloud run deploy insurance-agent \
  --source . \
  --region us-central1 \
  --allow-unauthenticated \
  --set-env-vars GEMINI_API_KEY=your_key
```

**Cost**: FREE tier includes 2M requests/month

---

### Option 2: Vertex AI (For Enterprise Scale)

**Create** `vertex_deploy.py`:
```python
from google.cloud import aiplatform

aiplatform.init(project="your-project-id", location="us-central1")

# Deploy model
endpoint = aiplatform.Endpoint.create(display_name="insurance-agent")

# Upload and deploy (simplified)
# Full code in documentation
```

**Cost**: $300 free credits for new users

---

## ðŸ“Š Workshop Recap

### What We Built:
âœ… Agentic AI with 6 core principles  
âœ… LangGraph orchestration with nodes & edges  
âœ… RAG system with Chroma + Gemini embeddings  
âœ… FastAPI backend  
âœ… Deployment-ready architecture  

### Technologies Used:
- **Google AI Studio**: Prototyping & API key
- **LangGraph**: Visual orchestration
- **Gemini 1.5 Flash**: LLM reasoning (FREE)
- **Chroma DB**: Vector storage (FREE)
- **FastAPI**: REST API
- **Cloud Run / Vertex AI**: Deployment

### Next Steps:
1. Add frontend (React + Vite)
2. Implement document upload (Gemini Vision)
3. Add more insurance types
4. Deploy to production
5. Monitor with LangSmith

---

## ðŸ“š Resources

- **Code Repository**: [Your GitHub Link]
- **Google AI Studio**: https://aistudio.google.com/
- **LangGraph Docs**: https://langchain-ai.github.io/langgraph/
- **Vertex AI**: https://cloud.google.com/vertex-ai

---

## ðŸŽ¯ Key Takeaways

1. **Agentic AI â‰  Chatbot**: It plans, reasons, and acts autonomously
2. **LangGraph**: Makes complex workflows visual and maintainable
3. **RAG**: Grounds responses in your knowledge base
4. **Google Stack**: 100% free for development and small-scale production
5. **Production-Ready**: Can scale to enterprise with Vertex AI

---

**Thank you for attending! Questions?** ðŸŽ‰

---

## Appendix: Complete File Structure

```
insurance-agent/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ .env                      # GEMINI_API_KEY
â”‚   â”œâ”€â”€ agent_state.py            # State definition
â”‚   â”œâ”€â”€ tools.py                  # Premium calculators
â”‚   â”œâ”€â”€ graph_nodes.py            # LangGraph nodes
â”‚   â”œâ”€â”€ langgraph_agent.py        # Graph workflow
â”‚   â”œâ”€â”€ rag_system.py             # Vector store
â”‚   â”œâ”€â”€ main.py                   # FastAPI app
â”‚   â”œâ”€â”€ requirements.txt          # Dependencies
â”‚   â””â”€â”€ insurance_knowledge_db/   # Chroma DB
â”‚
â”œâ”€â”€ frontend/                     # (Optional for workshop)
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ Dockerfile                    # For Cloud Run
â””â”€â”€ README.md                     # Documentation
```

---

## Appendix: requirements.txt

```
langchain==1.1.0
langgraph==1.0.4
langchain-google-genai==3.2.0
langchain-chroma==0.1.0
chromadb==0.5.5
fastapi==0.123.0
uvicorn==0.38.0
python-dotenv==1.2.1
pillow==11.0.0
pydantic==2.12.5
```

---

**END OF WORKSHOP GUIDE**

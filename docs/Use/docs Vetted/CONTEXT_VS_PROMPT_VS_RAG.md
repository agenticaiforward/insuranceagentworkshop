# ğŸ§  Context Engineering vs Prompt Engineering vs RAG
**Understanding the Three Pillars of AI Intelligence**

---

## ğŸ¯ Quick Comparison

| Aspect | Prompt Engineering | Context Engineering | RAG (Retrieval Augmented Generation) |
|--------|-------------------|---------------------|--------------------------------------|
| **What** | Design AI personality & behavior | Provide relevant info for THIS conversation | Search knowledge base for facts |
| **When** | Once, at design time | Every message | When user asks questions |
| **Who** | Orchestrators design | System provides automatically | System searches automatically |
| **Where** | System prompt | Conversation history | External knowledge base |
| **Example** | "You are a friendly agent" | "User said age is 28" | "Collision coverage definition" |

---

## ğŸ“Š Visual Comparison

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    USER MESSAGE                              â”‚
â”‚              "What is collision coverage?"                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â†“                   â†“                   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   PROMPT      â”‚  â”‚    CONTEXT       â”‚  â”‚     RAG      â”‚
â”‚ ENGINEERING   â”‚  â”‚  ENGINEERING     â”‚  â”‚   SEARCH     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“                   â†“                   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ "You are a    â”‚  â”‚ Previous msgs:   â”‚  â”‚ Knowledge:   â”‚
â”‚  friendly     â”‚  â”‚ - User: age 28   â”‚  â”‚ "Collision   â”‚
â”‚  insurance    â”‚  â”‚ - User: Honda    â”‚  â”‚  coverage    â”‚
â”‚  agent"       â”‚  â”‚ - AI: asked for  â”‚  â”‚  pays for    â”‚
â”‚               â”‚  â”‚   history        â”‚  â”‚  damage..."  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   GEMINI LLM  â”‚
                    â”‚   Combines    â”‚
                    â”‚   all three   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   RESPONSE    â”‚
                    â”‚ "Collision    â”‚
                    â”‚  coverage..." â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 1ï¸âƒ£ PROMPT ENGINEERING

### **What It Is**
Designing the AI's **personality, role, and behavior** that stays constant across all conversations.

### **Analogy**
Like hiring an employee and giving them a job description.

### **In the Workshop**
**Part 2 (15 min): Orchestrators design the agent's personality**

**Example Prompt**:
```
You are "Alex", an expert insurance agent powered by AI.

Your personality:
- Friendly and professional
- Patient and helpful
- Explains complex terms simply

Your role:
1. Help customers get accurate quotes
2. Answer questions about coverage
3. Gather required information

Guidelines:
- Ask 1-2 questions at a time
- Explain clearly when asked
- Calculate quote when ready
```

### **Code Location**
`backend/system_prompt.py`

```python
INSURANCE_AGENT_PROMPT = """
You are "Alex", an expert insurance agent...
"""
```

### **When It's Used**
- âœ… **Once** when agent starts
- âœ… **Same for all users**
- âœ… **Defines WHO the agent is**

### **Orchestrator Activity**
1. Open AI Studio
2. Design personality
3. Test with conversations
4. Refine based on results
5. Share with implementers

---

## 2ï¸âƒ£ CONTEXT ENGINEERING

### **What It Is**
Providing the AI with **relevant information from THIS specific conversation** so it remembers what was said.

### **Analogy**
Like taking notes during a meeting so you remember what was discussed.

### **In the Workshop**
**Part 3 (20 min): Implementers build conversation memory**

**Example Context**:
```
Conversation so far:
User: "I need car insurance"
AI: "I'd be happy to help! What's your age?"
User: "I'm 28"
AI: "Great! What vehicle do you drive?"
User: "2020 Honda Civic"
AI: "Perfect! How many years have you been licensed?"
```

### **Code Location**
`backend/main.py` (lines 132-142)

```python
# Get or create session
if session_id not in sessions:
    sessions[session_id] = {
        "messages": [],           # â† Context: conversation history
        "user_info": {},          # â† Context: extracted data
        "insurance_type": None,   # â† Context: what they need
        "quote_result": None,
        "knowledge_context": "",
        "next_action": "gather_info"
    }

session = sessions[session_id]

# Add user message to history
session["messages"].append(HumanMessage(content=request.message))
```

### **When It's Used**
- âœ… **Every message** in the conversation
- âœ… **Unique per user**
- âœ… **Defines WHAT was said**

### **Implementer Activity**
1. Store conversation history
2. Track extracted information
3. Pass to LLM with each message
4. Agent remembers context

### **Why It Matters**
**Without context**:
```
User: "I'm 28"
AI: "What's your age?"  â† Forgot user just said it!
```

**With context**:
```
User: "I'm 28"
AI: "Great! What vehicle do you drive?"  â† Remembers age
```

---

## 3ï¸âƒ£ RAG (Retrieval Augmented Generation)

### **What It Is**
**Searching a knowledge base** for facts and information to answer user questions accurately.

### **Analogy**
Like looking up information in a company handbook before answering.

### **In the Workshop**
**Part 4 (20 min): Orchestrators write FAQs, Implementers build search**

**Example Knowledge Base**:
```
Q: What is collision coverage?
A: Collision coverage pays for damage to YOUR vehicle when you hit 
   another vehicle or object, regardless of who's at fault.

Q: What is comprehensive coverage?
A: Comprehensive coverage pays for damage to your vehicle from 
   non-collision events like theft, vandalism, weather, or fire.

Q: How can I lower my premium?
A: Common ways include: bundling policies (10-25% off), maintaining 
   a clean driving record (15-30% off), and increasing deductible.
```

### **Code Location**
`backend/rag_system.py`

```python
# Knowledge base (from orchestrators!)
INSURANCE_KNOWLEDGE = {
    "auto_coverage": [
        "Collision coverage pays for damage to YOUR vehicle...",
        "Comprehensive coverage pays for damage from theft...",
        "Liability coverage pays for damage YOU cause..."
    ],
    "discounts": [
        "Bundling policies saves 10-25%...",
        "Clean driving record saves 15-30%..."
    ]
}

def search_knowledge(query: str, k: int = 2):
    """Search knowledge base for relevant information"""
    vectorstore = Chroma(...)
    results = vectorstore.similarity_search(query, k=k)
    return results
```

### **When It's Used**
- âœ… **When user asks questions** ("What is X?")
- âœ… **Searches external knowledge**
- âœ… **Provides FACTS to the agent**

### **Orchestrator Activity**
1. Write 10 insurance FAQs
2. Cover: coverage types, discounts, general
3. Keep answers clear
4. Share with implementers

### **Implementer Activity**
1. Add FAQs to `INSURANCE_KNOWLEDGE`
2. Initialize vector database
3. Implement search function
4. Integrate with chat endpoint

### **How It Works**
```
User asks: "What is collision coverage?"
         â†“
System detects question keyword ("what is")
         â†“
RAG searches knowledge base
         â†“
Finds: "Collision coverage pays for damage..."
         â†“
Adds to context for LLM
         â†“
LLM uses fact to answer accurately
```

---

## ğŸ”„ How They Work Together

### **Example Conversation**

**User**: "Hi, I need insurance"

**What happens**:
1. **Prompt Engineering**: Agent uses personality ("friendly, helpful")
2. **Context Engineering**: Stores message in history
3. **RAG**: Not triggered (no question asked)

**Response**: "I'd be happy to help! Are you looking for auto or home insurance?"

---

**User**: "Auto insurance. What's the difference between collision and comprehensive?"

**What happens**:
1. **Prompt Engineering**: Agent uses guideline ("explain clearly")
2. **Context Engineering**: Remembers user wants auto insurance
3. **RAG**: Searches knowledge base for "collision" and "comprehensive"

**RAG finds**:
```
- Collision: pays for damage to YOUR vehicle when you hit something
- Comprehensive: pays for damage from theft, weather, etc.
```

**Response**: "Great question! Collision coverage pays for damage to YOUR vehicle when you hit another vehicle or object. Comprehensive coverage pays for damage from non-collision events like theft, vandalism, or weather. Both are optional but recommended!"

---

**User**: "I'm 28, drive a 2020 Honda Civic"

**What happens**:
1. **Prompt Engineering**: Agent uses guideline ("ask 1-2 questions at a time")
2. **Context Engineering**: Stores age=28, vehicle=2020 Honda Civic
3. **RAG**: Not triggered (no question)

**Response**: "Perfect! How many years have you been licensed, and have you had any accidents or violations in the last 3 years?"

---

## ğŸ“Š Workshop Timeline

### **Part 2: Prompt Engineering (15 min)**
**Orchestrators**: Design agent personality in AI Studio
**Implementers**: Code `system_prompt.py`
**Together**: Test personality

### **Part 3: Context Engineering (20 min)**
**Orchestrators**: Create test cases
**Implementers**: Build LangGraph with state management
**Together**: Verify agent remembers context

### **Part 4: RAG (20 min)**
**Orchestrators**: Write 10 FAQs
**Implementers**: Implement vector search
**Together**: Test knowledge retrieval

---

## ğŸ¯ Key Differences

### **Prompt Engineering**
- âœ… **Static**: Same for all users
- âœ… **Design time**: Created once
- âœ… **Defines**: WHO the agent is
- âœ… **Example**: "You are friendly and professional"

### **Context Engineering**
- âœ… **Dynamic**: Unique per conversation
- âœ… **Runtime**: Updates every message
- âœ… **Defines**: WHAT was said
- âœ… **Example**: "User said age is 28"

### **RAG**
- âœ… **On-demand**: Only when needed
- âœ… **Query time**: Searches when user asks
- âœ… **Defines**: FACTS from knowledge base
- âœ… **Example**: "Collision coverage definition"

---

## ğŸ’¡ When to Use Each

### **Use Prompt Engineering When**:
- Defining agent personality
- Setting conversation guidelines
- Specifying required information
- Establishing tone and style

### **Use Context Engineering When**:
- Remembering user information
- Tracking conversation flow
- Avoiding repeated questions
- Maintaining state across messages

### **Use RAG When**:
- User asks factual questions
- Need accurate, up-to-date information
- Have large knowledge base
- Want to avoid hallucinations

---

## ğŸ§ª Hands-On Exercise

### **Test All Three**

**Scenario**: User asks about insurance

**Your Turn**:

1. **Prompt Engineering**: Design personality
```
You are [NAME], a [ROLE] with [PERSONALITY].
```

2. **Context Engineering**: Track this conversation
```
User: "I need car insurance"
AI: "What's your age?"
User: "28"
AI: [Should remember age, ask next question]
```

3. **RAG**: Write a FAQ
```
Q: What is liability coverage?
A: [Your answer]
```

---

## ğŸ“š Code Examples

### **1. Prompt Engineering**
```python
# backend/system_prompt.py
INSURANCE_AGENT_PROMPT = """
You are "Alex", an expert insurance agent.
Your personality: Friendly, professional, helpful
"""
```

### **2. Context Engineering**
```python
# backend/main.py
session = {
    "messages": [
        HumanMessage("I need insurance"),
        AIMessage("What's your age?"),
        HumanMessage("I'm 28")  # â† Context stored
    ],
    "user_info": {"age": 28}  # â† Extracted context
}
```

### **3. RAG**
```python
# backend/rag_system.py
INSURANCE_KNOWLEDGE = {
    "auto_coverage": [
        "Collision coverage pays for damage to YOUR vehicle..."
    ]
}

# Search when user asks
results = search_knowledge("What is collision coverage?")
# Returns: "Collision coverage pays for damage..."
```

---

## âœ… Summary Table

| Feature | Prompt Eng | Context Eng | RAG |
|---------|-----------|-------------|-----|
| **Frequency** | Once | Every message | On-demand |
| **Scope** | All users | Per user | Per question |
| **Storage** | Code | Memory | Database |
| **Created by** | Orchestrators | System | Orchestrators + System |
| **Purpose** | Define behavior | Remember conversation | Provide facts |
| **Example** | "Be friendly" | "User is 28" | "Collision = ..." |

---

## ğŸ“ Key Takeaways

1. **Prompt Engineering** = WHO the agent is (personality)
2. **Context Engineering** = WHAT was said (memory)
3. **RAG** = FACTS from knowledge base (search)

4. **All three work together** to create intelligent conversations

5. **Orchestrators design** prompts and knowledge
6. **Implementers build** context management and RAG
7. **Together** they create a smart agent

---

## ğŸ“– Workshop Resources

- **Prompt Engineering**: `docs/PROMPT_ENGINEERING_GUIDE.md`
- **Context Engineering**: See LangGraph agent state
- **RAG**: `backend/rag_system.py`

---

**Remember**: These aren't competing approaches - they complement each other! ğŸš€
